{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import time\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def parse_elements_in_soup(soup, \n",
    "                           index = False, \n",
    "                           chinese_dialect_list = ['Chinese', 'Mandarin', 'Cantonese']):\n",
    "\n",
    "    main_content = soup.find('div', id=\"main-content\")\n",
    "\n",
    "    # Select the header in main content\n",
    "\n",
    "    main_content_header = main_content.find('header')\n",
    "\n",
    "    '''information to export'''\n",
    "\n",
    "    try:\n",
    "        contact_name = main_content_header.find('h1').get_text()\n",
    "    except:\n",
    "        contact_name = np.nan\n",
    "\n",
    "    try:\n",
    "        profession = main_content_header.find('p').contents[0].strip()\n",
    "    except:\n",
    "        profession = np.nan\n",
    "\n",
    "    try:\n",
    "        date_admitted = main_content_header.find(\n",
    "            'p').contents[1].get_text().strip()\n",
    "    except:\n",
    "        date_admitted = np.nan\n",
    "\n",
    "    try:\n",
    "        sra_id = main_content_header.find('dl').contents[3].get_text().strip()\n",
    "    except:\n",
    "        sra_id = np.nan\n",
    "\n",
    "    try:\n",
    "        profession_related = main_content_header.find(\n",
    "            'dl').contents[5].get_text()\n",
    "    except:\n",
    "        profession_related = np.nan\n",
    "\n",
    "    # Select the details in main content\n",
    "\n",
    "    main_content_details = main_content.find('div', id='details-accordion')\n",
    "\n",
    "    # First Section: Contact and Organisation\n",
    "\n",
    "    section_contact = main_content_details.find('section')\n",
    "\n",
    "    '''information to export'''\n",
    "\n",
    "    try:\n",
    "        contact_tel = section_contact.find(\n",
    "            'dt', string='Tel:').find_next_sibling('dd').get_text()\n",
    "    except:\n",
    "        contact_tel = np.nan\n",
    "\n",
    "    try:\n",
    "        contact_email = section_contact.find(\n",
    "            'dt', id='Email').find_next_sibling().get_text().strip()\n",
    "    except:\n",
    "        contact_email = np.nan\n",
    "\n",
    "    try:\n",
    "        contact_organisation = section_contact.find(\n",
    "            'dt', string='Consultant at:').find_next_sibling('dd').find('a').get_text().strip()\n",
    "    except:\n",
    "        contact_organisation = np.nan\n",
    "\n",
    "    try:\n",
    "        contact_address = ' '.join([item.strip() for item in section_contact.find(\n",
    "            'dt', string='Consultant at:').find_next_sibling('dd').contents[4:-4:2]])\n",
    "    except:\n",
    "        contact_address = np.nan\n",
    "\n",
    "    try:\n",
    "        contact_dx_code = section_contact.find(\n",
    "            'dd', class_='feature highlight').get_text()\n",
    "    except:\n",
    "        contact_dx_code = np.nan\n",
    "\n",
    "    try:\n",
    "        roles_at_contact_organisation = section_contact.find(\n",
    "            'dt', string='Roles at this organisation').find_next_sibling('dd').get_text().strip()\n",
    "    except:\n",
    "        roles_at_contact_organisation = np.nan\n",
    "\n",
    "    # Third Section: Languages spoken\n",
    "\n",
    "    try:\n",
    "        languages_spoken_list = main_content_details.find(\n",
    "            'div', id=\"languages-spoken-accordion\").get_text().strip().split('\\n')\n",
    "        \n",
    "        is_speaking_chinese = any(dialect in languages_spoken_list for dialect in chinese_dialect_list)\n",
    "        languages_spoken = ', '.join(languages_spoken_list)\n",
    "        \n",
    "    except:\n",
    "        is_speaking_chinese = False\n",
    "        languages_spoken = np.nan\n",
    "        \n",
    "    if index:\n",
    "        entry_index = index\n",
    "    else:\n",
    "        entry_index = np.nan\n",
    "\n",
    "    data = {'entry_index': entry_index,\n",
    "            'contact_name': contact_name,\n",
    "            'profession': profession,\n",
    "            'date_admitted': date_admitted,\n",
    "            'sra_id': sra_id,\n",
    "            'profession_related': profession_related,\n",
    "            'contact_tel': contact_tel,\n",
    "            'contact_email': contact_email,\n",
    "            'contact_organisation': contact_organisation,\n",
    "            'contact_address': contact_address,\n",
    "            'contact_dx_code': contact_dx_code,\n",
    "            'roles_at_contact_organisation': roles_at_contact_organisation,\n",
    "            'languages_spoken': languages_spoken,\n",
    "            'is_speaking_chinese': is_speaking_chinese}\n",
    "\n",
    "    df_entry = pd.DataFrame.from_records([data])\n",
    "\n",
    "    return df_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def save_entry_to_db(df_entry, table_name = 'law_professionals_table', dbname = 'law_professionals_db'):\n",
    "\n",
    "    #pdb.set_trace()\n",
    "    conn = sqlite3.connect(dbname + '.sqlite')\n",
    "    df_entry.to_sql(name=table_name, con=conn, if_exists='append')\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def drop_table_in_db(table_name = 'law_professionals_table', dbname = 'law_professionals_db'):\n",
    "\n",
    "    conn = sqlite3.connect(dbname + '.sqlite')   \n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    dropTableStatement = \"DROP TABLE \" + table_name\n",
    "\n",
    "    cursor.execute(dropTableStatement)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def scrape_data_to_db(url, index=False):\n",
    "\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "\n",
    "    except:\n",
    "\n",
    "        entry_status = 3\n",
    "        print('Error ', str(entry_status), ': \\t',\n",
    "              'Network connection failed!')\n",
    "\n",
    "        return entry_status\n",
    "\n",
    "    entry_status = 0\n",
    "\n",
    "    # 0: 404,\n",
    "    # 1: 200 + don't speak Chinese,\n",
    "    # 2: 200 + speak Chinese,\n",
    "    # 3: network connection issue,\n",
    "    # 4: database connection issue, law_professionals_table,\n",
    "    # 5: database connection issue, chinese_speaking_law_professionals_table\n",
    "\n",
    "    if page.status_code == 200:\n",
    "\n",
    "        entry_status += 1\n",
    "\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        df_entry = parse_elements_in_soup(soup, index=index)\n",
    "\n",
    "        try:\n",
    "\n",
    "            save_entry_to_db(df_entry, table_name='law_professionals_table')\n",
    "\n",
    "        except:\n",
    "\n",
    "            entry_status = 4\n",
    "            print('Error ', str(entry_status), ': \\t',\n",
    "                  'Database connection issue, law_professionals_table!')\n",
    "\n",
    "            return entry_status\n",
    "\n",
    "        is_speaking_chinese = df_entry['is_speaking_chinese'].any()\n",
    "\n",
    "        if is_speaking_chinese:\n",
    "\n",
    "            entry_status += 1\n",
    "\n",
    "            try:\n",
    "                save_entry_to_db(\n",
    "                    df_entry, table_name='chinese_speaking_law_professionals_table')\n",
    "\n",
    "            except:\n",
    "\n",
    "                entry_status = 5\n",
    "                print('Error ', str(entry_status), ': \\t',\n",
    "                      'Database connection issue, chinese_speaking_law_professionals_table!')\n",
    "\n",
    "    return entry_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def scrape_pages_in_range(*arg,\n",
    "                          trials=50,\n",
    "                          reset_table_all=False,\n",
    "                          reset_table_chinese=False,\n",
    "                          base_url=\"https://solicitors.lawsociety.org.uk/person/\"):\n",
    "\n",
    "    if len(arg) == 0:\n",
    "\n",
    "        range_start, range_end = 0, 10\n",
    "\n",
    "    elif len(arg) == 1:\n",
    "\n",
    "        range_start, range_end = 0, arg[0]\n",
    "\n",
    "    else:\n",
    "\n",
    "        range_start, range_end = arg[0], arg[1]\n",
    "\n",
    "    if reset_table_all:\n",
    "\n",
    "        try:\n",
    "            drop_table_in_db(table_name='law_professionals_table')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if reset_table_chinese:\n",
    "\n",
    "        try:\n",
    "            drop_table_in_db(\n",
    "                table_name='chinese_speaking_law_professionals_table')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    status_labels = ['---', '-n-', '-y-']\n",
    "    status_counts = [0, 0, 0]\n",
    "    # [network, database_table_all, database_table_chinese]\n",
    "    errors_statistic = [0, 0, 0]\n",
    "\n",
    "    for index in range(range_start, range_end):\n",
    "\n",
    "        url = base_url + str(index)\n",
    "\n",
    "        while trials:\n",
    "\n",
    "            entry_status = scrape_data_to_db(url, index=index)\n",
    "\n",
    "            if entry_status < 3:\n",
    "\n",
    "                break\n",
    "\n",
    "            time.sleep(5)\n",
    "            errors_statistic[entry_status-3] += 1\n",
    "            trials -= 1\n",
    "            print('Errors statistic: ', str(errors_statistic),\n",
    "                  '\\t', 'Remaining number of trials: ', str(trials))\n",
    "\n",
    "        status_counts[entry_status] += 1\n",
    "\n",
    "        print(str(index).rjust(6) + \":\", '-'+ str(trials).zfill(2)+'-', \n",
    "              status_labels[entry_status], str(status_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : \t ------ \t [1, 0, 0]\n",
      "1 : \t ------ \t [2, 0, 0]\n",
      "2 : \t --no-- \t [2, 1, 0]\n",
      "3 : \t ------ \t [3, 1, 0]\n",
      "4 : \t ------ \t [4, 1, 0]\n",
      "5 : \t --no-- \t [4, 2, 0]\n",
      "6 : \t ------ \t [5, 2, 0]\n",
      "7 : \t --no-- \t [5, 3, 0]\n",
      "8 : \t --no-- \t [5, 4, 0]\n",
      "9 : \t --no-- \t [5, 5, 0]\n",
      "10 : \t --no-- \t [5, 6, 0]\n"
     ]
    }
   ],
   "source": [
    "scrape_pages_in_range(11, trials=1, reset_table_all=True, reset_table_chinese=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Command Line Arguments Explanation!')\n",
    "\n",
    "    parser.add_argument(\"range_params\", type=int, nargs='*',\n",
    "                        help=\"Parameter(s) for the index range() function\")\n",
    "\n",
    "    parser.add_argument(\"-a\", \"--reset_table_all\", default=False,\n",
    "                        action='store_true', help=\"Reset the table which has all the contacts\")\n",
    "    parser.add_argument(\"-c\", \"--reset_table_chinese\", default=False, action='store_true',\n",
    "                        help=\"Reset the table which has all the Chinese speaking contacts\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    scrape_pages_in_range(*args.range_params, reset_table_all=args.reset_table_all,\n",
    "                              reset_table_chinese=args.reset_table_chinese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single entry test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://solicitors.lawsociety.org.uk/person/42'\n",
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_content = soup.find('div', id=\"main-content\")\n",
    "main_content_details = main_content.find('div', id='details-accordion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_languages_spoken = main_content_details.find(\n",
    "    'div', id=\"languages-spoken-accordion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_spoken_list = section_languages_spoken.get_text().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_dialect_list = ['Chinese', 'Mandarin', 'Cantonese']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_spoken = ', '.join(languages_spoken_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_speaking_chinese = any(dialect in languages_spoken_list for dialect in chinese_dialect_list)\n",
    "is_speaking_chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cantonese', 'English', 'French', 'Mandarin', 'Spanish']\n"
     ]
    }
   ],
   "source": [
    "df = parse_elements_in_soup(soup, 42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
